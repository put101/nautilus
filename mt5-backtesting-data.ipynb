{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b39fb599655ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:29.853578Z",
     "start_time": "2023-12-10T20:51:29.623016Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56807e69c644985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:09:31.348099Z",
     "start_time": "2023-12-04T12:09:31.262693Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MT5 Imports\n",
    "import MetaTrader5 as mt5\n",
    "from MetaTrader5 import AccountInfo, TerminalInfo\n",
    "import importlib\n",
    "importlib.reload(mt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:35.118385Z",
     "start_time": "2023-12-10T20:51:33.869686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "#import naut_mt5 as n5\n",
    "#from naut_mt5 import data_utils\n",
    "\n",
    "import nautilus_trader\n",
    "# test instrument provider\n",
    "from nautilus_trader.test_kit.providers import TestInstrumentProvider\n",
    "from nautilus_trader.persistence.wranglers import QuoteTickDataWrangler\n",
    "from nautilus_trader.persistence.catalog import ParquetDataCatalog\n",
    "import os\n",
    "from nautilus_trader.data.engine import ParquetDataCatalog\n",
    "from nautilus_trader.model.instruments import Instrument\n",
    "from nautilus_trader.model.data import BarType, Bar\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from nautilus_trader.persistence.wranglers import BarDataWrangler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9701184c77bb6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:35.135792Z",
     "start_time": "2023-12-10T20:51:35.119492Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "if not dotenv.load_dotenv():\n",
    "    logging.log(logging.INFO, \"No .env file found\")\n",
    "\n",
    "dotenv.load_dotenv(override=True)\n",
    "MT5_SERVER = os.environ[\"MT5_SERVER\"]\n",
    "MT5_LOGIN = os.environ[\"MT5_LOGIN\"]\n",
    "MT5_PASSWORD = os.environ[\"MT5_PASSWORD\"]\n",
    "DATA_PATH = os.environ[\"DATA_PATH\"]\n",
    "CATALOG_PATH = os.environ[\"CATALOG_PATH\"]\n",
    "\n",
    "\n",
    "print(f\"MT5_SERVER: {MT5_SERVER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12c589e1282e88",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Symbol Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a20bae0af98d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:36.924501Z",
     "start_time": "2023-12-10T20:51:36.888342Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nautilus_trader.model.identifiers import InstrumentId, Venue\n",
    "from nautilus_trader.model.data import BarType, BarSpecification, BarAggregation\n",
    "from nautilus_trader.model.data import QuoteTick\n",
    "\n",
    "# load a couple of symbols into the catalog using the loader\n",
    "symbol_broker = 'XAUUSD'\n",
    "symbol_clean = 'XAUUSD'\n",
    "venue= \"SIM_IC\"\n",
    "instrument = TestInstrumentProvider.default_fx_ccy(symbol_clean, Venue(venue))\n",
    "timeframe = mt5.TIMEFRAME_M1\n",
    "start_date = datetime(1971, 1, 1)\n",
    "end_date = datetime.now()\n",
    "\n",
    "# variables dependent on parameters\n",
    "if symbol_clean:\n",
    "    symbol = symbol_clean\n",
    "else:\n",
    "    symbol = symbol_broker\n",
    "    \n",
    "loader_config = n5.MTLoginConfig(server=MT5_SERVER, login=MT5_LOGIN, password=MT5_PASSWORD)\n",
    "loader = n5.MT5Loader(data_path=DATA_PATH, catalog_path=CATALOG_PATH, config=loader_config, venue=venue)\n",
    "loader.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5.account_info().equity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba871caa92f6465a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Delete the symbol from the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7facef94b77cf82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T01:06:18.969303600Z",
     "start_time": "2023-12-02T01:06:17.598871300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete the symbols data from the catalog\n",
    "bar_type = loader.get_bar_type(symbol, timeframe)\n",
    "print(bar_type)\n",
    "\n",
    "if not data_utils.delete_parquet_data(bar_type, CATALOG_PATH):\n",
    "    print(f\"INFO: Could not delete\")\n",
    "else:\n",
    "    print(f\"INFO: Deleted data for {bar_type}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b6494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a31dfa35f608862",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load the symbol from mt5 to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd91d11fac5687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T01:06:26.110448500Z",
     "start_time": "2023-12-02T01:06:25.356622400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader.load_symbol_rates_to_csv(symbol_broker, symbol_clean, timeframe, start_date, end_date, DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0904a5c89bbcf4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load the symbol from csv to parquet catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487332cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautilus_trader.model.identifiers import InstrumentId, Venue, Symbol\n",
    "from nautilus_trader.model.data import BarType, BarSpecification, BarAggregation\n",
    "from nautilus_trader.model.data import QuoteTick\n",
    "from nautilus_trader.model.enums import AssetClass\n",
    "from nautilus_trader.model.instruments import CurrencyPair\n",
    "from nautilus_trader.model.instruments import Cfd\n",
    "from nautilus_trader.model.objects import Currency\n",
    "from nautilus_trader.model.objects import Money\n",
    "from nautilus_trader.model.objects import Price\n",
    "from nautilus_trader.model.objects import Quantity\n",
    "from nautilus_trader.model.currencies import USD\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = ParquetDataCatalog(\"./catalog\")\n",
    "symbol = Symbol(\"XAUUSD\")\n",
    "venue = Venue(\"SIM\")\n",
    "instrument_id = InstrumentId(symbol, venue)\n",
    "\n",
    "print(f\"Catalog: {catalog}\")\n",
    "print(f\"Symbol: {symbol}\")\n",
    "print(f\"Venue: {venue}\")\n",
    "print(f\"Instrument: {instrument_id}\")\n",
    "\n",
    "\n",
    "symbol_str = symbol.value\n",
    "base_currency = symbol_str[:3]\n",
    "quote_currency = symbol_str[-3:]\n",
    "price_precision = 2\n",
    "\n",
    "c = CurrencyPair(\n",
    "    instrument_id=instrument_id,\n",
    "    raw_symbol=symbol,\n",
    "    base_currency=Currency.from_str(base_currency),\n",
    "    quote_currency=Currency.from_str(quote_currency),\n",
    "    price_precision=price_precision,\n",
    "    size_precision=0,\n",
    "    price_increment=Price(1 / 10 ** price_precision, price_precision),\n",
    "    size_increment=Quantity.from_int(1),\n",
    "    lot_size=Quantity.from_str(\"100\"),\n",
    "    max_quantity=Quantity.from_str(\"1e7\"),\n",
    "    min_quantity=Quantity.from_str(\"1\"),\n",
    "    max_price=None,\n",
    "    min_price=None,\n",
    "    max_notional=Money(50_000_000.00, USD),\n",
    "    min_notional=Money(1.00, USD), # todo: check this\n",
    "    margin_init=Decimal(\"0.03\"),\n",
    "    margin_maint=Decimal(\"0.03\"),\n",
    "    maker_fee=Decimal(\"0.00002\"),\n",
    "    taker_fee=Decimal(\"0.00002\"),\n",
    "    ts_event=0,\n",
    "    ts_init=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.list_data_types()\n",
    "catalog.instruments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b48a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './XAUUSD_data_m1.csv'\n",
    "df = pd.read_csv(csv_path, index_col=\"time\", parse_dates=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_type = BarType.from_str(f\"{instrument_id}-1-MINUTE-MID-EXTERNAL\")\n",
    "print(f\"Bar type: {bar_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71294f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangler = BarDataWrangler(bar_type, instrument)\n",
    "bars: list[Bar] = wrangler.process(df)\n",
    "#basename_template = \"part-{i}\" + f\"-from-{int(start.timestamp())}-to-{int(end.timestamp())}\"\n",
    "print(f\"Bars: {bars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe145d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.write_data([instrument],)\n",
    "catalog.write_data(bars,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd8576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_bars(df: pd.DataFrame, bar_type: BarType, instrument: Instrument) -> list[Bar]:\n",
    "    wrangler = BarDataWrangler(bar_type, instrument)\n",
    "    bars: list[Bar] = wrangler.process(df)\n",
    "    return bars\n",
    "\n",
    "def bar_type_to_str(bar_type: BarType) -> str:\n",
    "    agg_src_mapping = {\n",
    "        1: 'EXTERNAL',\n",
    "        2: 'INTERNAL'\n",
    "    }\n",
    "    return f\"{bar_type.instrument_id}-{bar_type.spec}-{agg_src_mapping[bar_type.aggregation_source]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_bars(df: DataFrame, bar_type: BarType, instrument: Instrument) -> list[Bar]:\n",
    "    wrangler = BarDataWrangler(bar_type, instrument)\n",
    "    bars: list[Bar] = wrangler.process(df)\n",
    "    return bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create catalog directory if it doesn't exist\n",
    "if not os.path.exists(self.catalog_path):\n",
    "    print(f\"INFO: Creating catalog directory at: {self.catalog_path}\")\n",
    "    os.mkdir(self.catalog_path)\n",
    "\n",
    "instrument = TestInstrumentProvider.default_fx_ccy(symbol, self.venue)\n",
    "ticker_path = os.path.join(self.data_path, symbol.replace('/', '') + \".csv\")\n",
    "\n",
    "bar_type = self.get_bar_type(symbol=symbol, timeframe=timeframe)  # arbitrary? but .SIM-*** and meaningful name\n",
    "wrangler = BarDataWrangler(bar_type, instrument)\n",
    "bars: list[Bar] = wrangler.process(df)\n",
    "\n",
    "# instrument also has to be written in order to access data for the instrument\n",
    "catalog.write_data([instrument], \"part-{i}\")\n",
    "catalog.write_data(bars, basename_template=\"part-{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56301f7288dc35a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T01:06:41.682497200Z",
     "start_time": "2023-12-02T01:06:33.877177800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader.load_csv_to_catalog(symbol_broker, symbol_clean, timeframe, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ddd0552d466b9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T01:00:41.816088700Z",
     "start_time": "2023-11-27T01:00:41.724570300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instrument = loader.get_instrument_FOREX(symbol=symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41431731",
   "metadata": {},
   "source": [
    "# MT5 Ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import MetaTrader5 as mt5\n",
    "# display data on the MetaTrader 5 package\n",
    "print(\"MetaTrader5 package author: \",mt5.__author__)\n",
    "print(\"MetaTrader5 package version: \",mt5.__version__)\n",
    " \n",
    "# import the 'pandas' module for displaying data obtained in the tabular form\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500) # number of columns to be displayed\n",
    "pd.set_option('display.width', 1500)      # max table width to display\n",
    "# import pytz module for working with time zone\n",
    "import pytz\n",
    " \n",
    "# establish connection to MetaTrader 5 terminal\n",
    "if not mt5.initialize():\n",
    "    print(\"initialize() failed, error code =\",mt5.last_error())\n",
    "    quit()\n",
    " \n",
    "# set time zone to UTC\n",
    "timezone = pytz.timezone(\"Etc/UTC\")\n",
    "# create 'datetime' objects in UTC time zone to avoid the implementation of a local time zone offset\n",
    "utc_from = datetime(2020, 1, 10, tzinfo=timezone)\n",
    "utc_to = datetime(2020, 1, 11, hour = 13, tzinfo=timezone)\n",
    "# get bars from USDJPY M5 within the interval of 2020.01.10 00:00 - 2020.01.11 13:00 in UTC time zone\n",
    "rates = mt5.copy_rates_range(\"XAUUSD\", mt5.TIMEFRAME_M1, utc_from, utc_to)\n",
    " \n",
    "# shut down connection to the MetaTrader 5 terminal\n",
    "mt5.shutdown()\n",
    " \n",
    "# display each element of obtained data in a new line\n",
    "print(\"Display obtained data 'as is'\")\n",
    "counter=0\n",
    "for rate in rates:\n",
    "    counter+=1\n",
    "    if counter<=10:\n",
    "        print(rate)\n",
    " \n",
    "# create DataFrame out of the obtained data\n",
    "rates_frame = pd.DataFrame(rates)\n",
    "# convert time in seconds into the 'datetime' format\n",
    "rates_frame['time']=pd.to_datetime(rates_frame['time'], unit='s')\n",
    " \n",
    "# display data\n",
    "print(\"\\nDisplay dataframe with data\")\n",
    "print(rates_frame.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ed408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "\n",
    "mt5.initialize()\n",
    "maxbars = mt5.terminal_info().maxbars\n",
    "for count in range(maxbars):\n",
    "    rates = mt5.copy_rates_from_pos('XAUUSD', mt5.TIMEFRAME_M1, 0, 10000)\n",
    "    errno, strerror = mt5.last_error()\n",
    "    if errno != mt5.RES_S_OK:\n",
    "        print(f\"Failed on count={count} with strerror={strerror}\")\n",
    "        break\n",
    "mt5.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dcd6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_frame = pd.DataFrame(rates)\n",
    "rates_frame['time']=pd.to_datetime(rates_frame['time'], unit='s')\n",
    "rates_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef28154",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mt5.symbols_get(\"XAUUSD\"))\n",
    "print(mt5.account_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bfb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = mt5.positions_total()\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6aaf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5.initialize()\n",
    "ticks = mt5.copy_ticks_range(\"XAUUSD\", datetime(2024,1,1), datetime(2024,1,1), mt5.COPY_TICKS_ALL)\n",
    "df = pd.DataFrame(ticks)\n",
    "df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.copy_rates_range(\"XAUUSD\", timeframe, datetime(2023,1,1), datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215a652",
   "metadata": {},
   "source": [
    "## Copy Rates to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1040e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def download_and_save_data(symbol, timeframe, start_pos, num_bars, chunk_size, csv_filename, parquet_filename):\n",
    "    # Initialize MetaTrader 5 connection\n",
    "    if not mt5.initialize():\n",
    "        print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "        return\n",
    "    \n",
    "    # Create empty list to store rates\n",
    "    all_rates = []\n",
    "    \n",
    "    # Check if files already exist\n",
    "    csv_exists = os.path.exists(csv_filename)\n",
    "    parquet_exists = os.path.exists(parquet_filename)\n",
    "    \n",
    "    # Download the data in chunks\n",
    "    for i in range(0, num_bars, chunk_size):\n",
    "        chunk_bars = min(chunk_size, num_bars - i)\n",
    "        \n",
    "        # Fetch the data for the chunk\n",
    "        rates = mt5.copy_rates_from_pos(symbol, timeframe, start_pos + i, chunk_bars)\n",
    "        \n",
    "        if rates is None:\n",
    "            print(f\"Error retrieving data at position {start_pos + i}.\")\n",
    "            errno, strerror = mt5.last_error()\n",
    "            if errno != mt5.RES_S_OK:\n",
    "                print(f\"Failed on count={count} with strerror={strerror}\")\n",
    "            break\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        rates_frame = pd.DataFrame(rates)\n",
    "        rates_frame['time'] = pd.to_datetime(rates_frame['time'], unit='s')\n",
    "        \n",
    "        # Append to CSV\n",
    "        rates_frame.to_csv(\n",
    "            csv_filename, \n",
    "            mode='a', \n",
    "            header=not csv_exists,  # Write header only if file doesn't exist\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Append to Parquet\n",
    "        if parquet_exists:\n",
    "            rates_frame.to_parquet(\n",
    "                parquet_filename, \n",
    "                engine='fastparquet', \n",
    "                append=True,  # Append data if file exists\n",
    "                index=False\n",
    "            )\n",
    "        else:\n",
    "            rates_frame.to_parquet(\n",
    "                parquet_filename, \n",
    "                engine='fastparquet', \n",
    "                index=False\n",
    "            )\n",
    "            parquet_exists = True  # Update the flag\n",
    "        \n",
    "        # Update progress\n",
    "        print(f\"Saved {len(rates_frame)} rows to CSV and Parquet.\")\n",
    "        csv_exists = True  # Update the flag\n",
    "    \n",
    "    # Shutdown MetaTrader 5 connection\n",
    "    mt5.shutdown()\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "# Parameters\n",
    "symbol = \"XAUUSD\"\n",
    "timeframe = mt5.TIMEFRAME_M1  # Daily bars\n",
    "timeframe_str = \"m1\"\n",
    "start_pos = 0\n",
    "num_bars = 100000000  # Total number of bars you want to download\n",
    "chunk_size = 1000  # Size of each chunk to download at a time\n",
    "csv_filename = f\"{symbol}_data_{timeframe_str}.csv\"\n",
    "parquet_filename = f\"{symbol}_data_{timeframe_str}.parquet\"\n",
    "\n",
    "# Call the function to download and save the data\n",
    "download_and_save_data(symbol, timeframe, start_pos, num_bars, chunk_size, csv_filename, parquet_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1e7301eed868b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load a mt5 csv ticks file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.sql(\"from parquet_scan('XAUUSD_data_m1.parquet')\").fetchdf()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df['time'], df['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543b7488146c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:47.952639Z",
     "start_time": "2023-12-10T20:51:47.915827Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_file = os.path.join(DATA_PATH, \"EURUSD.i_201808220305_202312012359.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e54165475d82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:48.048913Z",
     "start_time": "2023-12-10T20:51:48.028609Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_start = pd.Timestamp(\"201808220305\") \n",
    "ts_end = pd.Timestamp(\"202312012359\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db28ceac3c14b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:48.248253Z",
     "start_time": "2023-12-10T20:51:48.226654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df: pd.DataFrame = dd.read_csv(csv_file, header=0, sep=\"\\t\", parse_dates={'time' : [0, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818c59c1aeac0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:48.800309Z",
     "start_time": "2023-12-10T20:51:48.779471Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time    <BID>    <ASK>   <LAST> <VOLUME> <FLAGS>\n",
    "#new_columns = ['time', 'bid', 'ask', 'last', 'volume', 'flags']\n",
    "#df = df.rename(columns=dict(zip(df.columns, new_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46d99fd5bdc5fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:51:48.952255Z",
     "start_time": "2023-12-10T20:51:48.932507Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrangler = QuoteTickDataWrangler(instrument)\n",
    "catalog = ParquetDataCatalog(CATALOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5e427291862e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T22:04:16.624687Z",
     "start_time": "2023-12-10T20:55:02.637120Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process the csv: \n",
    "chunk_size = 10**6 # ticks per parquet file\n",
    "i=0\n",
    "\n",
    "for chunk in pd.read_csv(csv_file, sep='\\t', chunksize=chunk_size):\n",
    "    chunk['time'] = pd.to_datetime(chunk['<DATE>'] + ' ' +  chunk['<TIME>'])\n",
    "    chunk.set_index('time', inplace=True)\n",
    "    new_columns = ['date', 'time', 'bid', 'ask', 'last', 'volume', 'flags']\n",
    "    chunk = chunk.rename(columns=dict(zip(chunk.columns, new_columns)))\n",
    "    chunk: pd.DataFrame = chunk.drop(['date','time'], axis=1)\n",
    "    \n",
    "    # process\n",
    "    if i == 0:\n",
    "        catalog.write_data([instrument])\n",
    "    \n",
    "    # metadata\n",
    "    # first timestamp\n",
    "    ts_start = chunk.index[0]\n",
    "    # last timestamp\n",
    "    ts_end = chunk.index[-1]\n",
    "    \n",
    "    # i got some weird ouliers in the resulting df and want to log\n",
    "    # if they are from the filling or from the data\n",
    "    \n",
    "    # log nans indexes and print values after the fill\n",
    "    nans = chunk[chunk.isna().any(axis=1)]\n",
    "    \n",
    "    min_bid_before = min(chunk['bid'].values)\n",
    "    min_ask_before = min(chunk['ask'].values)\n",
    "    \n",
    "    print(f\"min bid before: {min_bid_before}\")\n",
    "    print(f\"min ask before: {min_ask_before}\")\n",
    "    \n",
    "    if len(nans) > 0:\n",
    "        print(f\"found {len(nans)} nans in chunk {i}\")\n",
    "    \n",
    "    # important! fill the nans with previous values\n",
    "    chunk = chunk.fillna(method='bfill')\n",
    "    chunk = chunk.fillna(method='ffill')\n",
    "    # many nans cause mid price to be half of actual price because some nans remain and get to be filled with 0\n",
    "    # fill nans that still remain with following values\n",
    "    \n",
    "    min_bid_after = min(chunk['bid'].values)\n",
    "    min_ask_after = min(chunk['ask'].values)\n",
    "    \n",
    "    print(f\"min bid after: {min_bid_after}\")\n",
    "    print(f\"min ask after: {min_ask_after}\")\n",
    "    \n",
    "    \n",
    "    # log min value of ƒilled nans\n",
    "    min(nans['bid'].values)\n",
    "    min(nans['ask'].values)\n",
    "    \n",
    "    \n",
    "    ticks: list[QuoteTick] =  wrangler.process(chunk)\n",
    "    catalog.write_data(ticks, basename_template=f\"chunk-{i}\")\n",
    "    print(f\"written {chunk_size} ticks to: chunk-{i} {ts_start} {ts_end}\")\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81673dbdbe3074a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:05.293150Z",
     "start_time": "2023-12-04T19:46:05.282804Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from last big import of EUR/USD\n",
    "# written 1000000 ticks to: chunk-136 2023-11-13 18:03:49.591000 2023-12-01 23:59:56.437000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9a1a1e9d4e269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:05.663835Z",
     "start_time": "2023-12-04T19:46:05.624370Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.Timestamp(1534907125665000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05b4345378eab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:05.989247Z",
     "start_time": "2023-12-04T19:46:05.963632Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Timestamp(1544908782211000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4afb53bfd7952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:06.162749Z",
     "start_time": "2023-12-04T19:46:06.113328Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ticks = catalog.quote_ticks(instrument_ids=[instrument.symbol.value], start = pd.Timestamp(1534907125665000000), end=pd.Timestamp(1534909125665000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24583c769a6aadab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:06.538149Z",
     "start_time": "2023-12-04T19:46:06.261927Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3dfd2b8347156a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:12.610992Z",
     "start_time": "2023-12-04T19:46:12.569477Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asks = [t.ask_price for t in ticks]\n",
    "asks = np.array(asks)\n",
    "asks[asks == 0] = np.nan\n",
    "# fill nans with previous value\n",
    "asks = pd.Series(asks).fillna(method='ffill').values\n",
    "\n",
    "ts = [t.ts_event for t in ticks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8635b4310962ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:12.700515Z",
     "start_time": "2023-12-04T19:46:12.657540Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nanos to timestamp\n",
    "ts = np.array(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3becd7ab10f9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:12.784077Z",
     "start_time": "2023-12-04T19:46:12.761448Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = pd.to_datetime(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2384acc66a37d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T19:46:13.390795Z",
     "start_time": "2023-12-04T19:46:13.220637Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ts, asks, label='ask' )\n",
    "# plt.plot(bids, x, label='bid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1f633432c5855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:50:23.603145Z",
     "start_time": "2023-12-04T17:50:23.463184Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa79bcd9a66e135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:50:26.619274Z",
     "start_time": "2023-12-04T17:50:26.574123Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ffae3870ba017",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
